{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a39b55d-2579-48e1-abea-043d99474a93",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c799f-562c-4ff7-b112-14b658d5b353",
   "metadata": {},
   "source": [
    "### Public documentation resources on working with GPUs\n",
    "\n",
    "[1] https://cloud.google.com/vertex-ai/docs/training/distributed-training#additional-worker-pools\n",
    "\n",
    "[2] https://cloud.google.com/compute/docs/gpus#a100-gpus\n",
    "\n",
    "[3] https://cloud.google.com/compute/docs/gpus#h100-gpus\n",
    "\n",
    "[4] https://cloud.google.com/compute/docs/gpus#t4-gpus\n",
    "\n",
    "[5] https://cloud.google.com/compute/docs/general-purpose-machines#n1_machine_types\n",
    "\n",
    "[6] https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types\n",
    "\n",
    "[7] https://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus\n",
    "\n",
    "[8] https://cloud.google.com/vertex-ai/docs/general/locations#accelerators\n",
    "\n",
    "[9] https://cloud.google.com/vertex-ai/docs/training/persistent-resource-overview\n",
    "\n",
    "[10] https://cloud.google.com/vertex-ai/docs/quotas#training\n",
    "\n",
    "[11] https://cloud.google.com/vertex-ai/docs/training/persistent-resource-create#create-persistent-resource-python\n",
    "\n",
    "[12] https://cloud.google.com/vertex-ai/docs/training/persistent-resource-train#create_a_training_job_that_runs_on_a_persistent_resource\n",
    "\n",
    "[13] https://cloud.google.com/vertex-ai/docs/workbench/reference/rest/v1/projects.locations.executions/create\n",
    "\n",
    "[14] https://cloud.google.com/vertex-ai/docs/workbench/reference/rest/v1/ExecutionTemplate\n",
    "\n",
    "[15] https://cloud.google.com/compute/docs/gpus/gpu-regions-zones\n",
    "\n",
    "[16] https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "\n",
    "---\n",
    "\n",
    "- gcr.io/deeplearning-platform-release/pytorch-gpu.1-13.py310:latest\n",
    "  - NVIDIA-SMI `550.54.15`\n",
    "  - Driver Version: `550.54.15`\n",
    "  - CUDA Version: `12.4`\n",
    "  - Torch: `1.13.1+cu117`\n",
    "  - Torch: `['sm_37', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'sm_80', 'sm_86']`\n",
    "\n",
    "- gcr.io/deeplearning-platform-release/pytorch-gpu.2-1.py310:latest\n",
    "  - NVIDIA-SMI `550.54.15`\n",
    "  - Driver Version: `550.54.15`\n",
    "  - CUDA Version: `12.4`\n",
    "  - Torch: `2.1.0+cu121`\n",
    "  - Torch: `['sm_50', 'sm_60', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']`\n",
    "\n",
    "- gcr.io/deeplearning-platform-release/pytorch-gpu.2-2.py310:latest\n",
    "  - NVIDIA-SMI `550.54.15`\n",
    "  - Driver Version: `550.54.15`\n",
    "  - CUDA Version: `12.4`\n",
    "  \n",
    "PyTorch compatibility with NVIDIA GPUs:\n",
    "  \n",
    "https://developer.nvidia.com/cuda-gpus\n",
    "\n",
    "https://discuss.pytorch.org/t/gpu-compute-capability-support-for-each-pytorch-version/62434/7?u=daniel_elias\n",
    "\n",
    "https://discuss.pytorch.org/t/which-pytorch-version-is-compatible-with-h100-gpu-and-cuda-capability-sm-90/202966/2\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "[a] https://cloud.google.com/compute/docs/gpus#h100-gpus\n",
    "\n",
    "[b] https://cloud.google.com/vertex-ai/docs/training/code-requirements#gpus\n",
    "\n",
    "[c] https://discuss.pytorch.org/t/rnn-module-weights-are-not-part-of-single-contiguous-chunk-of-memory/6011\n",
    "\n",
    "[d] https://discuss.pytorch.org/t/difference-between-cuda-0-vs-cuda-with-1-gpu/93080\n",
    "\n",
    "[e] https://stackoverflow.com/questions/50495053/if-im-not-specifying-to-use-cpu-gpu-which-one-is-my-script-using\n",
    "\n",
    "[f] https://stackoverflow.com/questions/72610665/in-the-latest-version-of-pytorch-what-is-best-practice-to-get-all-tensors-to-us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e0889-56c9-4f6f-9320-28222b93d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILED_PIPELINE_JSON = \"custom_training_pipeline.json\"\n",
    "\n",
    "PROJECT_ID = \"PROJECT-ID\"\n",
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs://training-custom-gpus-unique-PROJECT-ID\"\n",
    "PIPELINE_DISPLAY_NAME = \"training-with-gpus-job\"\n",
    "SCRIPT_PATH = \"trainer.py\"\n",
    "#https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "# gcr.io/deeplearning-platform-release/pytorch-gpu.1-13.py310:latest\n",
    "# gcr.io/deeplearning-platform-release/pytorch-gpu.2-2.py310:latest\n",
    "# gcr.io/deeplearning-platform-release/pytorch-gpu.2-1.py310:latest\n",
    "CONTAINER_URI = \"gcr.io/deeplearning-platform-release/pytorch-gpu.2-1.py310:latest\"\n",
    "CONTAINER_URI_NO_GPU = \"python:3.9\"\n",
    "REPLICA_COUNT = 1\n",
    "# https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types\n",
    "# https://cloud.google.com/compute/docs/general-purpose-machines#n1_machine_types\n",
    "MACHINE_TYPE=\"n1-highmem-96\"\n",
    "# https://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus\n",
    "# https://cloud.google.com/compute/docs/gpus#a100-gpus\n",
    "# https://cloud.google.com/compute/docs/gpus#h100-gpus\n",
    "# https://cloud.google.com/compute/docs/gpus#t4-gpus\n",
    "ACCELERATOR_TYPE=\"NVIDIA_TESLA_T4\"\n",
    "ACCELERATOR_COUNT=4\n",
    "\n",
    "PERSISTENT_RESOURCE_ID = \"cluster-vertex-ai-training-t4-gpus\"\n",
    "BOOT_DISK_TYPE=\"pd-standard\"\n",
    "BOOT_DISK_SIZE=100\n",
    "\n",
    "SCRIPT = \"\"\"\n",
    "import os\n",
    "\n",
    "print('hello world')\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_arch_list())\n",
    "\n",
    "os.system('nvidia-smi --query-gpu=compute_cap --format=csv')\n",
    "\n",
    "os.system('nvidia-smi -L')\n",
    "os.system('nvidia-smi')\n",
    "os.system('cat /proc/meminfo')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8dc5ef-7f0b-4a36-b16b-da36970a3d03",
   "metadata": {},
   "source": [
    "# Custom Training Job\n",
    "\n",
    "You can run the training job directly in Vertex AI Training without the need of a Vertex AI Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d948a2-804c-4cbf-b1d7-5ec3b1cf379f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5a44b-bbf5-45fb-bd32-daa9e0e21867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_training_job(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    staging_bucket: str,\n",
    "    script_path: str,\n",
    "    container_uri: str,\n",
    "    replica_count: int = 0,\n",
    "    machine_type: str = \"n1-standard-4\",\n",
    "    accelerator_type: str = \"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "    accelerator_count: int = 0,\n",
    "    boot_disk_type: str = \"pd-ssd\",\n",
    "    boot_disk_size_gb: int = 100,\n",
    "    persistent_resource_id: str = \"\",\n",
    "    script: str = \"print('hello world')\",\n",
    "    #args: [List[Union[str, float, int]]] = None,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location, staging_bucket=staging_bucket)\n",
    "    \n",
    "    # write trainer script to be used - this is just for demonstration purposes\n",
    "    file_object = open(script_path, \"w\")\n",
    "    file_object.write(script)\n",
    "    file_object.close()\n",
    "    \n",
    "    # Main one to use persistent resources: google.cloud.aiplatform.CustomJob\n",
    "    # https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script\n",
    "    # Another one google.cloud.aiplatform.CustomTrainingJob -> This one includes also uploading model to Model Registry but I don't see persistent training\n",
    "    # https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob#google_cloud_aiplatform_CustomTrainingJob\n",
    "    \n",
    "    job = aiplatform.CustomJob.from_local_script(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        display_name=display_name,\n",
    "        staging_bucket=staging_bucket,\n",
    "        script_path=script_path, # training code/script needs to be accessible from inside the container that runs the job\n",
    "        container_uri=container_uri,\n",
    "        replica_count=1,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        persistent_resource_id=persistent_resource_id,\n",
    "        boot_disk_type=boot_disk_type,\n",
    "        boot_disk_size_gb=boot_disk_size_gb,\n",
    "        #args=['--dataset', 'gs://my-bucket/my-dataset'],\n",
    "    )\n",
    "\n",
    "    job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fd66c-01ce-48ae-877e-0b369a14b16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#os.chdir('/home/jupyter')\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fda10b-b417-49d9-b9fc-0d2b485e6940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "create_custom_training_job(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    display_name=PIPELINE_DISPLAY_NAME,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    "    script_path=SCRIPT_PATH,\n",
    "    container_uri=CONTAINER_URI,\n",
    "    #container_uri=CONTAINER_URI_NO_GPU,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    persistent_resource_id=PERSISTENT_RESOURCE_ID,\n",
    "    boot_disk_type=BOOT_DISK_TYPE,\n",
    "    boot_disk_size_gb=BOOT_DISK_SIZE,\n",
    "    script=SCRIPT\n",
    "    #args=,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16e5c1-4ab5-4314-bcc1-54386332a6cc",
   "metadata": {},
   "source": [
    "# Pipeline to trigger a Custom Training Job\n",
    "\n",
    "In case you need to trigger the Vertex AI Training Job through a Vertex AI Pipeline.\n",
    "\n",
    "The Vertex AI Pipeline will also appear as a Vertex AI Training Custom Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8758303-0337-44da-b8a1-5d073de68ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6829f-5508-4e12-b3bf-f994277a6b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Pipeline\n",
    "# https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/pipelines_intro_kfp.ipynb\n",
    "\n",
    "from kfp import dsl\n",
    "from typing import Any, Callable\n",
    "from kfp import compiler\n",
    "\n",
    "# https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "# Select an image that has aiplatform installed for example 'gcr.io/deeplearning-platform-release/pytorch-gpu.1-13.py310:latest'\n",
    "@dsl.component(base_image='gcr.io/deeplearning-platform-release/pytorch-gpu.2-2.py310:latest')\n",
    "# 'gcr.io/deeplearning-platform-release/pytorch-gpu.1-13.py310:latest'\n",
    "def create_custom_training_job(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    staging_bucket: str,\n",
    "    script_path: str,\n",
    "    container_uri: str,\n",
    "    replica_count: int = 0,\n",
    "    machine_type: str = \"n1-standard-4\",\n",
    "    accelerator_type: str = \"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "    accelerator_count: int = 0,\n",
    "    boot_disk_type: str = \"pd-ssd\",\n",
    "    boot_disk_size_gb: int = 100,\n",
    "    persistent_resource_id: str = \"\",\n",
    "    script: str = \"print('hello world')\",\n",
    "    #args: [List[Union[str, float, int]]] = None,\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=location, staging_bucket=staging_bucket)\n",
    "    \n",
    "    # Main one to use persistent resources: google.cloud.aiplatform.CustomJob\n",
    "    # https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script\n",
    "    # Another one google.cloud.aiplatform.CustomTrainingJob -> This one includes also uploading model to Model Registry but I don't see persistent training\n",
    "    # https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob#google_cloud_aiplatform_CustomTrainingJob\n",
    "    \n",
    "    # write trainer script to be used - this is just for demonstration purposes\n",
    "    file_object = open(script_path, \"w\")\n",
    "    file_object.write(script)\n",
    "    file_object.close()\n",
    "    \n",
    "    job = aiplatform.CustomJob.from_local_script(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        display_name=display_name,\n",
    "        staging_bucket=staging_bucket,\n",
    "        script_path=script_path, # training code/script needs to be accessible from inside the container that runs the job\n",
    "        container_uri=container_uri,\n",
    "        replica_count=1,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        persistent_resource_id=persistent_resource_id,\n",
    "        boot_disk_type=boot_disk_type,\n",
    "        boot_disk_size_gb=boot_disk_size_gb,\n",
    "        #args=['--dataset', 'gs://my-bucket/my-dataset'],\n",
    "    )\n",
    "\n",
    "    job.run()\n",
    "\n",
    "@dsl.pipeline (name=PIPELINE_DISPLAY_NAME + \"-pipeline\")\n",
    "def custom_training_pipeline():\n",
    "        create_custom_training_job(\n",
    "        project=PROJECT_ID,\n",
    "        location=LOCATION,\n",
    "        display_name=PIPELINE_DISPLAY_NAME,\n",
    "        staging_bucket=STAGING_BUCKET,\n",
    "        script_path=SCRIPT_PATH,\n",
    "        container_uri=CONTAINER_URI,\n",
    "        replica_count=REPLICA_COUNT,\n",
    "        machine_type=MACHINE_TYPE,\n",
    "        accelerator_type=ACCELERATOR_TYPE,\n",
    "        accelerator_count=ACCELERATOR_COUNT,\n",
    "        persistent_resource_id=PERSISTENT_RESOURCE_ID,\n",
    "        boot_disk_type=BOOT_DISK_TYPE,\n",
    "        boot_disk_size_gb=BOOT_DISK_SIZE,\n",
    "        script=SCRIPT\n",
    "        #args=,\n",
    "    )\n",
    "\n",
    "def compile_pipeline(func: Callable, file_name: str) -> None:\n",
    "    compiler.Compiler().compile(func, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d93f29-fccc-4950-9ccf-4da8afefa6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compile_pipeline(custom_training_pipeline, COMPILED_PIPELINE_JSON)\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "# https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/pipelines_intro_kfp.ipynb\n",
    "\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=PIPELINE_DISPLAY_NAME,\n",
    "    template_path=COMPILED_PIPELINE_JSON\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
